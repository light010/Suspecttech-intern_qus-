{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network structure for this sample:\n",
    "#\n",
    "# .....................         (input data, gray scale)        [32, 32]\n",
    "# :::::::::                       W1[3, 3, 4]      B1[4]\n",
    "#   @ @ @ @ @ @ @           --  convnet layer, stride 2\n",
    "#                           --  Y1[16, 16, 4]    =>  reshape to YY[1024, 1]\n",
    "#     :::::                      W2[10, 1024]     B2[10]\n",
    "#    \\x/x\\x/x\\              -- Fully connected layer\n",
    "#    .....                      Y2[10, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* image dimension is given as (32, 32) that means image is of a gray scale.\n",
    "* filter size is given as -> (filter_width = 3, filter_hight = 3, # of channels = 4)\n",
    "* total no. of channels in filter is 4 so no. of required biases will also be 4 sclar no.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.randint(0, 256, size=(32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as image is an array of dimension (32, 32) where each no. will be between 0(black) to 255(white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4  # convolution layer output depth\n",
    "L = 10 # fully connected layer\n",
    "\n",
    "# for convolution layer\n",
    "W1 = np.random.normal(0, 0.1, (3, 3, 1, K))       \n",
    "B1 = np.ones(4)/10\n",
    "\n",
    "# for fully connected layer\n",
    "W2 = np.random.normal(0, 0.1, (L, 1024))\n",
    "B2 = np.ones((10,1))/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(img, filtr, bias, stride):\n",
    "    \n",
    "    input_w, input_h = img.shape[1], img.shape[0]\n",
    "    filtr_w, filtr_h = filtr.shape[1], filtr.shape[0]\n",
    "    \n",
    "    output_depth = filtr.shape[3]\n",
    "    output_w = int(np.ceil((input_w - filtr_w)/stride) + 1)\n",
    "    output_h = int(np.ceil((input_w - filtr_w)/stride) + 1)\n",
    "    output = np.zeros((output_h, output_w, output_depth))\n",
    "    \n",
    "    for x in range(output_w-1):\n",
    "        for y in range(output_h-1):\n",
    "            for z in range(output_depth):\n",
    "                output[x,y,z] = (filtr[:,:,:,z] * img[x*stride : x*stride+filtr_w, \n",
    "                                                    y*stride : y*stride+filtr_h]).sum() + B1[z]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as padding is restricted in the qus, so we can not put 16 as a range for x and y. becoz if we do then it will raise an error stating (3,3)_filter size_ can not be multiplited with (3,2)_leftover image patch_.<br>\n",
    "so here we are only taking 15 grid of output matrix into consideration and will put zeros in the 16th grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(output):\n",
    "    return np.maximum(0, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution output\n",
    "Y1 = relu(conv2d(img, W1, B1, stride=2))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping this output for fully connected layer operation\n",
    "YY = np.reshape(Y1, (1024, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = np.matmul(W2, YY) + B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output size\n",
    "Y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  34.77854787],\n",
       "       [ -80.99800497],\n",
       "       [  42.17065842],\n",
       "       [-124.3558209 ],\n",
       "       [  27.94392921],\n",
       "       [ 114.21073589],\n",
       "       [-136.57048817],\n",
       "       [ 128.42036919],\n",
       "       [-202.18998645],\n",
       "       [  15.94743505]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
